dataset: 'CREMAD'
modulation: 'OGM_GE'
fusion_method: 'concat'
fps: 1
num_classes: 7
audio_path: './cremad-1/cremad/AudioWAV/'  # fix link dataset
visual_path: './cremad-1/cremad/'  # fix link dataset
batch_size: 16
epochs: 30
optimizer: 'sgd'
learning_rate: 0.0002
lr_decay_step: 70
lr_decay_ratio: 0.1
momentum: 0.9
ckpt_path: './ckpt'
train: true
use_tensorboard: false
tensorboard_path: null
random_seed: 0
input_tdim: 256
epoch: 100
weight_visual: './weight-cremad/weight.pth'
weight_audio: './weight-asr/audioset_10_10_0.4593.pth'
save_path: './weight.pth'  # fix link save weight
train_csv: './data/CREMAD/train.csv'  # Path to train.csv
test_csv: './data/CREMAD/test.csv'  # Path to test.csv
img_size: 224  # Image size for PatchEmbed
patch_size: 16  # Patch size for PatchEmbed
in_chans: 3  # Input channels for PatchEmbed
embed_dim: 768  # Embedding dimension for PatchEmbed
fstride: 10  # Frequency stride
tstride: 10  # Time stride
input_fdim: 128  # Number of frequency bins
input_tdim: 1024  # Number of time frames
imagenet_pretrain: true  # Use ImageNet pretrained model
audioset_pretrain: true  # Use AudioSet pretrained model
model_size: 'base384'  # Model size for ASTModel
# Visual model parameters
visual_model:
  reduction_ratio: 16  # Reduction ratio for ChannelGate
  pool_types: ['avg', 'max']  # Pool types used in ChannelGate
# MANet parameters
manet:
  layers: [2, 2, 2, 2]  # Layers for MANet
  num_classes: 12666  # Number of output classes for MANet
